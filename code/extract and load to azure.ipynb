{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa340476-aab7-43f3-99eb-fcf67ca91cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in /opt/anaconda3/lib/python3.12/site-packages (1.7.4.2)\n",
      "Requirement already satisfied: bleach in /opt/anaconda3/lib/python3.12/site-packages (from kaggle) (4.1.0)\n",
      "Requirement already satisfied: certifi>=14.05.14 in /opt/anaconda3/lib/python3.12/site-packages (from kaggle) (2025.1.31)\n",
      "Requirement already satisfied: charset-normalizer in /opt/anaconda3/lib/python3.12/site-packages (from kaggle) (3.3.2)\n",
      "Requirement already satisfied: idna in /opt/anaconda3/lib/python3.12/site-packages (from kaggle) (3.7)\n",
      "Requirement already satisfied: protobuf in /opt/anaconda3/lib/python3.12/site-packages (from kaggle) (4.25.3)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /opt/anaconda3/lib/python3.12/site-packages (from kaggle) (2.9.0.post0)\n",
      "Requirement already satisfied: python-slugify in /opt/anaconda3/lib/python3.12/site-packages (from kaggle) (5.0.2)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from kaggle) (2.32.3)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from kaggle) (75.1.0)\n",
      "Requirement already satisfied: six>=1.10 in /opt/anaconda3/lib/python3.12/site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: text-unidecode in /opt/anaconda3/lib/python3.12/site-packages (from kaggle) (1.3)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from kaggle) (4.66.5)\n",
      "Requirement already satisfied: urllib3>=1.15.1 in /opt/anaconda3/lib/python3.12/site-packages (from kaggle) (2.2.3)\n",
      "Requirement already satisfied: webencodings in /opt/anaconda3/lib/python3.12/site-packages (from kaggle) (0.5.1)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.12/site-packages (from bleach->kaggle) (24.1)\n",
      "Collecting azure-storage-file-datalake\n",
      "  Downloading azure_storage_file_datalake-12.20.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: azure-core>=1.30.0 in /opt/anaconda3/lib/python3.12/site-packages (from azure-storage-file-datalake) (1.34.0)\n",
      "Requirement already satisfied: azure-storage-blob>=12.25.1 in /opt/anaconda3/lib/python3.12/site-packages (from azure-storage-file-datalake) (12.25.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from azure-storage-file-datalake) (4.11.0)\n",
      "Requirement already satisfied: isodate>=0.6.1 in /opt/anaconda3/lib/python3.12/site-packages (from azure-storage-file-datalake) (0.7.2)\n",
      "Requirement already satisfied: requests>=2.21.0 in /opt/anaconda3/lib/python3.12/site-packages (from azure-core>=1.30.0->azure-storage-file-datalake) (2.32.3)\n",
      "Requirement already satisfied: six>=1.11.0 in /opt/anaconda3/lib/python3.12/site-packages (from azure-core>=1.30.0->azure-storage-file-datalake) (1.16.0)\n",
      "Requirement already satisfied: cryptography>=2.1.4 in /opt/anaconda3/lib/python3.12/site-packages (from azure-storage-blob>=12.25.1->azure-storage-file-datalake) (43.0.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/anaconda3/lib/python3.12/site-packages (from cryptography>=2.1.4->azure-storage-blob>=12.25.1->azure-storage-file-datalake) (1.17.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.21.0->azure-core>=1.30.0->azure-storage-file-datalake) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.21.0->azure-core>=1.30.0->azure-storage-file-datalake) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.21.0->azure-core>=1.30.0->azure-storage-file-datalake) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.21.0->azure-core>=1.30.0->azure-storage-file-datalake) (2025.1.31)\n",
      "Requirement already satisfied: pycparser in /opt/anaconda3/lib/python3.12/site-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob>=12.25.1->azure-storage-file-datalake) (2.21)\n",
      "Downloading azure_storage_file_datalake-12.20.0-py3-none-any.whl (263 kB)\n",
      "Installing collected packages: azure-storage-file-datalake\n",
      "Successfully installed azure-storage-file-datalake-12.20.0\n"
     ]
    }
   ],
   "source": [
    "!pip install kaggle\n",
    "!pip install azure-storage-file-datalake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bdb0c59-f1b1-451e-8e69-66c3a95b3953",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "from azure.storage.filedatalake import DataLakeServiceClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "280b0ef8-2d98-44a1-86e7-b1fac02182de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading dataset to ./Olist/raw-data...\n",
      "Dataset URL: https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce\n",
      "Uploading olist_sellers_dataset.csv as sellers.csv...\n",
      "Uploaded as sellers.csv\n",
      "Uploading product_category_name_translation.csv as product_category_name_translation.csv...\n",
      "Uploaded as product_category_name_translation.csv\n",
      "Uploading olist_orders_dataset.csv as orders.csv...\n",
      "Uploaded as orders.csv\n",
      "Uploading olist_order_items_dataset.csv as order_items.csv...\n",
      "Uploaded as order_items.csv\n",
      "Uploading olist_customers_dataset.csv as customers.csv...\n",
      "Uploaded as customers.csv\n",
      "Uploading olist_geolocation_dataset.csv as geolocation.csv...\n",
      "Uploaded as geolocation.csv\n",
      "Uploading olist_order_payments_dataset.csv as order_payment.csv...\n",
      "Uploaded as order_payment.csv\n",
      "Uploading olist_order_reviews_dataset.csv as order_reviews.csv...\n",
      "Uploaded as order_reviews.csv\n",
      "Uploading olist_products_dataset.csv as products.csv...\n",
      "Uploaded as products.csv\n",
      "All files uploaded successfully!\n"
     ]
    }
   ],
   "source": [
    "def download_and_upload_dataset():\n",
    "    # Authenticate with Kaggle\n",
    "    api = KaggleApi()\n",
    "    api.authenticate()\n",
    "\n",
    "    # ADLS Gen2 connection string and container\n",
    "    connection_string = # <-- insert the azure connection string here\n",
    "    container_name = \"raw-data\"\n",
    "\n",
    "    # Local folders\n",
    "    base_dir = './Olist'\n",
    "    raw_data_dir = os.path.join(base_dir, 'raw-data')\n",
    "    os.makedirs(raw_data_dir, exist_ok=True)\n",
    "\n",
    "    print(f\"Downloading dataset to {raw_data_dir}...\")\n",
    "    api.dataset_download_files(dataset='olistbr/brazilian-ecommerce', path=raw_data_dir, unzip=True)\n",
    "\n",
    "    # File renaming map\n",
    "    rename_map = {\n",
    "        \"olist_customers_dataset.csv\": \"customers.csv\",\n",
    "        \"olist_geolocation_dataset.csv\": \"geolocation.csv\",\n",
    "        \"olist_order_items_dataset.csv\": \"order_items.csv\",\n",
    "        \"olist_order_payments_dataset.csv\": \"order_payment.csv\",\n",
    "        \"olist_order_reviews_dataset.csv\": \"order_reviews.csv\",\n",
    "        \"olist_orders_dataset.csv\": \"orders.csv\",\n",
    "        \"olist_products_dataset.csv\": \"products.csv\",\n",
    "        \"olist_sellers_dataset.csv\": \"sellers.csv\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # ADLS Gen2 upload\n",
    "        service_client = DataLakeServiceClient.from_connection_string(connection_string)\n",
    "        file_system_client = service_client.get_file_system_client(file_system=container_name)\n",
    "\n",
    "        for file_path in Path(raw_data_dir).glob('*.csv'):\n",
    "            original_name = file_path.name\n",
    "            new_name = rename_map.get(original_name, original_name)\n",
    "\n",
    "            print(f\"Uploading {original_name} as {new_name}...\")\n",
    "\n",
    "            file_client = file_system_client.get_file_client(new_name)\n",
    "            with open(file_path, \"rb\") as data:\n",
    "                file_contents = data.read()\n",
    "                file_client.create_file()\n",
    "                file_client.append_data(data=file_contents, offset=0, length=len(file_contents))\n",
    "                file_client.flush_data(len(file_contents))\n",
    "\n",
    "            print(f\"Uploaded as {new_name}\")\n",
    "\n",
    "        print(\"All files uploaded successfully!\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ADLS Gen2 upload error: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    download_and_upload_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc522ebb-2c68-4035-8ad2-57a54ba2bb0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
